{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from scipy.signal import butter, filtfilt\r\n",
    "from functools import partial"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3164/539028379.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbutter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiltfilt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mfunctools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpartial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def joints_filter(data):\r\n",
    "    f = 6 # Filter frequency\r\n",
    "    fs = 100 # Hz\r\n",
    "    low_pass = f/(fs/2)\r\n",
    "    b2, a2 = butter(N=2, Wn=low_pass, btype='lowpass')\r\n",
    "    columns = data.columns[1:]\r\n",
    "    for col in columns:\r\n",
    "        data[col] = filtfilt(b2, a2, data[col])\r\n",
    "    return data\r\n",
    "\r\n",
    "def load_IK(ik_file):\r\n",
    "    \"\"\"\r\n",
    "    ik_file: full extension name\r\n",
    "    \"\"\"\r\n",
    "    IK = pd.read_csv(ik_file ,header=8, sep='\\t', usecols=[0,10,11,17,18])\r\n",
    "    return IK\r\n",
    "\r\n",
    "def load_ID(id_file):\r\n",
    "    \"\"\"\r\n",
    "    id_file: file_name/.sto\r\n",
    "    \"\"\"\r\n",
    "    ID = pd.read_csv(id_file, header=6, sep='\\t', usecols=[0,16,17,18,19])\r\n",
    "    ID = ID_col_arranger(ID)\r\n",
    "    return ID\r\n",
    "\r\n",
    "def load_time_intervals(events_file):\r\n",
    "    \"\"\"\r\n",
    "    From motion file, find the times where you want to do the estimation and save the results in 3 columns\r\n",
    "    time, get_left_data, get_right_data.\r\n",
    "    get_left_data: boolen column. To make this column find when subject on force plate, and then find the\r\n",
    "    first TO before it and first HS after it, this range will be TRUE (use some saftey factor)\r\n",
    "    \"\"\"\r\n",
    "    events = pd.read_csv(events_file)\r\n",
    "    custom_around_func = partial(np.around, decimals=2)\r\n",
    "    events['time'] = events['time'].apply(custom_around_func)\r\n",
    "    return events\r\n",
    "\r\n",
    "def merge_joints(IK,ID,events):\r\n",
    "    # Merge kinematics and kinetics data\r\n",
    "    joints_data = pd.merge(IK, ID, on='time', how='inner')\r\n",
    "    # Assert no data loss\r\n",
    "    assert len(joints_data)==len(ID)==len(IK)\r\n",
    "    # low pass filtering OpenSim data\r\n",
    "#     joints_data = joints_filter(joints_data)\r\n",
    "    # Merge the columns that tells when to make measurements\r\n",
    "    joints_data_with_events = pd.merge(joints_data, events, on='time', how='inner')\r\n",
    "    # Assert no data lost\r\n",
    "    assert len(joints_data_with_events)==len(joints_data)\r\n",
    "    # Reset time to zero to match EMG\r\n",
    "    joints_data_with_events = reset_time(joints_data_with_events)\r\n",
    "    return joints_data_with_events\r\n",
    "\r\n",
    "def load_features(features_file):\r\n",
    "    \"\"\"\r\n",
    "    features_file: .csv file\r\n",
    "    \"\"\"\r\n",
    "    features = pd.read_csv(features_file, index_col='time')\r\n",
    "    return features\r\n",
    "\r\n",
    "def merge_IO(features, joints_data):\r\n",
    "    \"\"\"\r\n",
    "    downsampling is hold while merging by removing points\r\n",
    "    \"\"\"\r\n",
    "    Dataset = pd.merge(left=features, right=joints_data, on='time', how='inner')\r\n",
    "    assert len(Dataset)==len(features)\r\n",
    "    Dataset.set_index(\"time\", inplace=True)\r\n",
    "    return Dataset\r\n",
    "\r\n",
    "def ID_col_arranger(ID):\r\n",
    "    col = ID.columns\r\n",
    "    return ID[[col[0], col[1], col[3], col[2], col[4]]]\r\n",
    "\r\n",
    "def reset_time(data):\r\n",
    "    start_time = data['time'].min()\r\n",
    "    data['time'] = data['time'].apply(lambda x:x-start_time)\r\n",
    "    data['time'] = np.around(data['time'], 2)\r\n",
    "    return data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def get_dataset(subject=None):\r\n",
    "    if subject==None:\r\n",
    "        subject = input(\"Please write subject number in a format XX: \")\r\n",
    "    \r\n",
    "    files = [f'S{subject}_test', f'S{subject}_train_01', f'S{subject}_train_02', f'S{subject}_val']\r\n",
    "    settings = pd.read_csv(f\"../settings/dataset_settings/S{subject}_dataset_settings.csv\", header=None)\r\n",
    "    \r\n",
    "    ik_path = settings.iloc[0,1]\r\n",
    "    IK_files = list(map(lambda x: f\"{ik_path}{x}_IK.mot\", files))\r\n",
    "\r\n",
    "    id_path = settings.iloc[1,1]\r\n",
    "    ID_files = list(map(lambda x: f\"{id_path}{x}/inverse_dynamics.sto\", files))\r\n",
    "    \r\n",
    "    events_path = settings.iloc[2,1]\r\n",
    "    events_files = list(map(lambda x: f\"{events_path}{x}_events.csv\", files))\r\n",
    "    \r\n",
    "    features_path = settings.iloc[3,1]\r\n",
    "    Features_files = list(map(lambda x: f\"{features_path}{x}_features.csv\", files))\r\n",
    "\r\n",
    "    output_folder = settings.iloc[4,1]\r\n",
    "    output_files = list(map(lambda x: f\"{output_folder}{x}_dataset.csv\", files))\r\n",
    "    \r\n",
    "    for ik_file, id_file, events_file, features_file, output_name\\\r\n",
    "        in zip(IK_files,ID_files, events_files, Features_files, output_files):\r\n",
    "        \r\n",
    "        IK = load_IK(ik_file)\r\n",
    "        ID = load_ID(id_file)\r\n",
    "        events = load_time_intervals(events_file)\r\n",
    "        features = load_features(features_file)\r\n",
    "        joints_data = merge_joints(IK,ID, events)\r\n",
    "        Dataset = merge_IO(features, joints_data)\r\n",
    "        Dataset.loc[Dataset['L_side_select']==False,\r\n",
    "                    ['knee_angle_l_moment','ankle_angle_l_moment']]=np.nan\r\n",
    "        \r\n",
    "        Dataset.loc[Dataset['R_side_select']==False,\r\n",
    "                    ['knee_angle_r_moment','ankle_angle_r_moment']]=np.nan\r\n",
    "        \r\n",
    "        Dataset.drop(columns=['L_side_select', 'R_side_select'], inplace=True)\r\n",
    "        Dataset.to_csv(output_name)\r\n",
    "    print(\"DONE!\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "get_dataset()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Please write subject number in a format XX:  02\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DONE!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit (windows store)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "interpreter": {
   "hash": "a81d037db1f92518c5488e1b33cb54e2887351eb4b14af165208837517c9c99d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}