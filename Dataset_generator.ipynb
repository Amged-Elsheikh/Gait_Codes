{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_IK(ik_file):\n",
    "    \"\"\"\n",
    "    Load knee and ankle joints angles\n",
    "    ik_file: full extension name\n",
    "    \"\"\"\n",
    "    IK = pd.read_csv(ik_file, header=8, sep='\\t', usecols=[0, 10, 11, 17, 18])\n",
    "    return IK\n",
    "\n",
    "\n",
    "def load_ID(id_file):\n",
    "    \"\"\"\n",
    "    load knee and ankle joints moments\n",
    "    id_file: full extension name\n",
    "    \"\"\"\n",
    "    ID = pd.read_csv(id_file, header=6, sep='\\t', usecols=[0, 16, 17, 18, 19])\n",
    "    return ID_col_arranger(ID) # Return re-arranged columns\n",
    "\n",
    "\n",
    "def load_time_intervals(periods_file):\n",
    "    \"\"\"\n",
    "    Load recording periods.\n",
    "    periods_file: full name extension\n",
    "    \"\"\"\n",
    "    periods = pd.read_csv(periods_file, index_col=\"time\")\n",
    "    return periods\n",
    "\n",
    "\n",
    "def merge_joints(IK, ID, periods):\n",
    "    # Merge kinematics and kinetics data\n",
    "    joints_data = pd.merge(IK, ID, on='time', how='inner')\n",
    "    # Assert no data loss\n",
    "    assert len(joints_data) == len(ID) == len(IK)\n",
    "    # Merge the columns that tells when to make measurements (record periods)\n",
    "    joints_data_with_events = pd.merge(joints_data, periods, on='time', how='inner')\n",
    "    # Assert no data lost\n",
    "    assert len(joints_data_with_events) == len(joints_data)\n",
    "    # Reset time to zero to match EMG\n",
    "    joints_data_with_events = reset_time(joints_data_with_events)\n",
    "    return joints_data_with_events\n",
    "\n",
    "\n",
    "def load_features(features_file):\n",
    "    \"\"\"\n",
    "    features_file: .csv file\n",
    "    \"\"\"\n",
    "    features = pd.read_csv(features_file, index_col='time')\n",
    "    return features\n",
    "\n",
    "\n",
    "def merge_IO(features, joints_data):\n",
    "    \"\"\"\n",
    "    downsampling is hold while merging by removing points\n",
    "    \"\"\"\n",
    "    # Merge all features and joints. Down sampling is done while merging\n",
    "    Dataset = pd.merge(left=features, right=joints_data, on='time', how='inner')\n",
    "    Dataset.set_index(\"time\", inplace=True)\n",
    "    return Dataset\n",
    "\n",
    "\n",
    "def ID_col_arranger(ID):\n",
    "    \"\"\"\n",
    "    Arrange ID data columns to be:\n",
    "        ['time', 'knee_angle_r_moment', 'knee_angle_l_moment',\n",
    "                'ankle_angle_r_moment', 'ankle_angle_l_moment']\n",
    "    \"\"\"\n",
    "    col = ID.columns\n",
    "    return ID[[col[0], col[1], col[3], col[2], col[4]]]\n",
    "\n",
    "\n",
    "def reset_time(data):\n",
    "    start_time = data['time'].min()\n",
    "    data['time'] = data['time'].apply(lambda x: x-start_time)\n",
    "    data['time'] = np.around(data['time'], 3)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(subject=None):\n",
    "    if subject == None:\n",
    "        subject = input(\"Please write subject number in a format XX: \")\n",
    "\n",
    "    files = [f'S{subject}_test', f'S{subject}_train_01',\n",
    "             f'S{subject}_train_02', f'S{subject}_val']\n",
    "    settings = pd.read_csv(\n",
    "        f\"../settings/dataset_settings/S{subject}_dataset_settings.csv\", header=None)\n",
    "\n",
    "    ik_path = settings.iloc[0, 1]\n",
    "    IK_files = list(map(lambda x: f\"{ik_path}{x}_IK.mot\", files))\n",
    "\n",
    "    id_path = settings.iloc[1, 1]\n",
    "    ID_files = list(map(lambda x: f\"{id_path}{x}/inverse_dynamics.sto\", files))\n",
    "\n",
    "    record_periods_path = settings.iloc[2, 1]\n",
    "    periods_files = list(\n",
    "        map(lambda x: f\"{record_periods_path}{x}_record_periods.csv\", files))\n",
    "\n",
    "    features_path = settings.iloc[3, 1]\n",
    "    Features_files = list(\n",
    "        map(lambda x: f\"{features_path}{x}_features.csv\", files))\n",
    "\n",
    "    output_folder = settings.iloc[4, 1]\n",
    "    output_files = list(\n",
    "        map(lambda x: f\"{output_folder}{x}_dataset.csv\", files))\n",
    "\n",
    "    for ik_file, id_file, periods_file, features_file, output_name\\\n",
    "            in zip(IK_files, ID_files, periods_files, Features_files, output_files):\n",
    "\n",
    "        IK = load_IK(ik_file)\n",
    "        ID = load_ID(id_file)\n",
    "        periods = load_time_intervals(periods_file)\n",
    "        features = load_features(features_file)\n",
    "        joints_data = merge_joints(IK, ID, periods)\n",
    "        Dataset = merge_IO(features, joints_data)\n",
    "        Dataset.loc[Dataset['left_side'] == False, ['knee_angle_l_moment', 'ankle_angle_l_moment']] = np.nan\n",
    "\n",
    "        Dataset.loc[Dataset['right_side'] == False, ['knee_angle_r_moment', 'ankle_angle_r_moment']] = np.nan\n",
    "\n",
    "        Dataset.drop(columns=['left_side', 'right_side'], inplace=True) # Drop periods columns\n",
    "        Dataset.to_csv(output_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dataset()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "afc33188c16c8cc145c39cb16c5899af2377d7c1938c3d65488f8f079b28d1bf"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('tensor': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
